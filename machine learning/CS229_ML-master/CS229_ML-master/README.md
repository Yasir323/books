![Hits](https://hitcounter.pythonanywhere.com/count/tag.svg?url=https%3A%2F%2Fgithub.com%2FSKKSaikia%2FCS229_ML)

# [CS229 : Machine Learning](http://cs229.stanford.edu/)

<img src="https://github.com/SKKSaikia/CS229_ML/blob/master/img/cs229.jpg">

The "ML" course at Stanford , or to say the most popular Machine Learning course Worldwide is CS229. CS229 is Math Heavy and is ðŸ”¥, unlike a simplified online version at Coursera, "[Machine Learning](https://www.coursera.org/learn/machine-learning)". I [completed](https://www.coursera.org/account/accomplishments/verify/4G25AQXD9LDG) the [online](https://github.com/rmarquis/coursera-machinelearning) [version](https://github.com/atinesh-s/Coursera-Machine-Learning-Stanford) as a Freshaman and here I take the CS229 Stanford version. I have access to the 2013 video lectures of CS229 from [ClassX](http://classx.stanford.edu/) and the publicly available 2008 version is great as well. All in all, we have the slides, notes from the course website to learn the content. Stay truthful, maintain Honor Code and Keep Learning. Learning is a journey! 

No Text , but [Pattern Classification - Richard Duda, Peter Hart and David Stork](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/Pattern%20Classification%20by%20Richard%20O.%20Duda%2C%20David%20G.%20Stork%2C%20Peter%20E.Hart%20.pdf) | [handout](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/handout.pdf) | [Syllabus](http://cs229.stanford.edu/syllabus.html) 

ð“„† <b>Important Books : </b><br/>
ð“Š– [Hands on Machine Learning with Scikit Learn and TensorFlow](https://github.com/devakar/deep-learning-books/blob/master/Hands%20on%20Machine%20Learning%20with%20Scikit%20Learn%20and%20TensorFlow.pdf) <br/>
ð“Š– [Introduction to Machine Learning - Ethem AlpaydÄ±n](https://kkpatel7.files.wordpress.com/2015/04/alppaydin_machinelearning_2010.pdf) <br/>
ð“Š– [Machine Learning A Probabilistic Perspective](https://doc.lagout.org/science/Artificial%20Intelligence/Machine%20learning/Machine%20Learning_%20A%20Probabilistic%20Perspective%20%5BMurphy%202012-08-24%5D.pdf) <br/>
ð“Š– [Optimization for Machine Learning](https://doc.lagout.org/science/Artificial%20Intelligence/Machine%20learning/Optimization%20for%20Machine%20Learning%20%5BSra%2C%20Nowozin%20%26%20Wright%202011-09-30%5D.pdf) <br/>
ð“Š– [Pattern Recognition and Machine Learning - Bishop](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf) <br/>
ð“Š– [Pattern Recognition and Machine Learning Solution](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/Pattern%20Recognition%20and%20Machine%20Learning%20Solution.pdf) <br/>

<b> Homework (40%) + Mid-term (20%) + Final Project (40%) </b>

# ðŸ¥¤ Homeworks ([Problem Sets](https://github.com/SKKSaikia/CS229_ML/tree/master/PSET)): [Solutions](https://github.com/SKKSaikia/CS229_ML/blob/master/SOLUTIONS.MD)

ðŸ›¦ [PSET 0](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps0.pdf) <br/>
ðŸ›¦ [PSET 1](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps1.zip) - [inst](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps1.txt) - [testdata](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/data.zip)<br/> 
ðŸ›¦ [PSET 2](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps2.zip) - [inst](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps2.txt) <br/>
ðŸ›¦ [PSET 3](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps3.zip) - [inst](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps3.txt) - [peppers_numpy](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/peppers_numpy.zip) <br/>
ðŸ›¦ [PSET 4](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps4_v5_release.zip) - [inst](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/ps4.txt) - [autograder&solution](https://github.com/SKKSaikia/CS229_ML/blob/master/PSET/2018/autograder.zip) <br/>

# Course:

<p align="justify">This course provides a broad introduction to <b>machine learning</b> and <b>statistical pattern recognition</b>. Topics include: <b>supervised learning</b> (generative/discriminative learning, parametric/non-parametric learning, neural networks, support vector machines); <b>unsupervised learning</b> (clustering, dimensionality reduction, kernel methods); <b>learning theory</b> (bias/variance tradeoffs; VC theory; large margins); <b>reinforcement learning and adaptive control</b>. The course will also discuss recent applications of machine learning, such as to robotic control, data mining, autonomous navigation, bioinformatics, speech recognition, and text and web data processing.</p>

<h2><b> â™ž INTRODUCTION </b></h2>

ð“€½ Basic concepts.

<h2><b> â™ž SUPERVISED LEARNING </b></h2>

ð“€½ Supervised learning setup. LMS. [Supervised Learning, Discriminative Algorithms](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes1.pdf) <br/>
ð“€½ Logistic regression. Perceptron. Exponential family. [Linear Algebra](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/1%20-%20cs229-linalg.pdf) <br/>
ð“€½ Generative learning algorithms. Gaussian discriminant analysis. Naive Bayes. <br/>
ð“€½ [Support Vector Machines](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes2.pdf) <br/>
ð“€½ Model selection and feature selection, [Probability](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/2%20-%20cs229-prob.pdf) <br/>
ð“€½ Evaluating and debugging learning algorithms, [Python](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/CS229_Python_Tutorial.pdf) <br/>

<h2><b> â™ž LEARNING THEORY </b></h2>

ð“€½ [Advice on applying machine learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/ml_application_advice.pdf), [Bias/variance tradeoff](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes4a.pdf) and [error analysis](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes4b.pdf) <br/>
ð“€½ [Regularization and Model Selection](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes5.pdf) <br/>
ð“€½ Practical advice on how to use learning algorithms. <br/>

<h2><b> â™ž DEEP LEARNING </b></h2>

ð“€½ Neural Networks, [Deep Learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes-deep_learning.pdf), [Backpropagation](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes-backprop.pdf), [Trees](http://cs229.stanford.edu/notes/rf-notes.pdf) <br/>
ð“€½ [Online Learning and the Perceptron Algorithm](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes6.pdf), Vectorization. <br/>

<h2><b> â™ž UNSUPERVISED LEARNING </b></h2>

ð“€½ Clustering. [Unsupervised Learning, k-means clustering](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes7a.pdf) <br/>
ð“€½ [EM Algorithm](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes8.pdf). [Mixture of Gaussians](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes7b.pdf) <br/>
ð“€½ [Factor analysis](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes9.pdf) <br/>
ð“€½ PCA ([Principal components analysis](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes10.pdf)) <br/>
ð“€½ ICA ([Independent components analysis](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes11.pdf)) <br/>

<h2><b> â™ž REINFORCEMENT LEARNING AND CONTROL </b></h2>

ð“€½ MDPs. Bellman equations, [Reinforcement Learning and Control](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes12.pdf) <br/>
ð“€½ Value iteration and policy iteration. Linear quadratic regulation (LQR), [LQR, DDP and LQG](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/cs229-notes13.pdf) <br/>
ð“€½ Q-learning. Value function approximation. Policy search. Reinforce. POMDPs. <br/>
ð“€½ [On critiques of Machine Learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/critiques-ml.pdf) <br/>

<h2><b> Supplementary Notes </b></h2>

â™š Binary classification with +/-1 labels [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/supplementary_notes/1%20-%20loss-functions.pdf) <br/>
â™š Boosting algorithms and weak learning [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/supplementary_notes/2%20-%20boosting.pdf) <br/>
â™š Functional after implementing stump_booster.m in PS2. [here](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/supplementary_notes/3%20-%20boosting_example.m) <br/>
â™š The representer theorem [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/supplementary_notes/4%20-%20representer-function.pdf) <br/>
â™š Hoeffding's inequality [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/supplementary_notes/5%20-%20hoeffding.pdf) <br/>

<h2><b> Section Notes </b></h2>

â™š Linear Algebra Review and Reference [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/1%20-%20cs229-linalg.pdf) <br/>
â™š Probability Theory Review [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/2%20-%20cs229-prob.pdf) <br/>
â™š Convex Optimization Overview, Part I [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/4%20-%20cs229-cvxopt.pdf) <br/>
â™š Convex Optimization Overview, Part II [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/5%20-%20cs229-cvxopt2.pdf) <br/>
â™š Hidden Markov Models [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/6%20-%20cs229-hmm.pdf) <br/>
â™š The Multivariate Gaussian Distribution [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/7%20-%20gaussians.pdf) <br/>
â™š More on Gaussian Distribution [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/8%20-%20more_on_gaussians.pdf) <br/>
â™š Gaussian Processes [pdf](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/NOTES/section_notes/9%20-%20cs229-gaussian_processes.pdf) <br/>

[Exams](https://github.com/SKKSaikia/CS229_ML/tree/master/Exams) - [2018 Autumn](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/MTfinalTBA_aut_2018.pdf), â›· [2017_Autumn](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/2017_Aut_Midterm.pdf) : [Solution](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/2017_Aut_Midterm_soln.pdf), â›· [2016 Spring](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/2016_Spr_Midterm.pdf) : [Solution](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/2016_Spr_Midterm_soln.pdf), â›· [2016 Autumn](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/2016_Aut_Midterm.pdf) : [Solution](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/2016_Aut_Midterm_2.pdf), â›· [2015 Autumn](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/midterm2015.pdf) : [Solution](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/practicemidterm2sol.pdf), â›· [2014 Autumn](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/midterm2014.pdf) : [Solution](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/practicemidterm1sol.pdf), â›· [MReview](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/cs229-mt-review.pdf)  | Collected from public resources

âš· [My Solutions for CS229 Exams - 2018, 2017, 2016](https://github.com/SKKSaikia/CS229_ML/blob/master/Exams/SOLUTIONS.MD)

âœ¿ [MIT ML](http://machinelearning.mit.edu/) | [ML Cheatsheet](https://ml-cheatsheet.readthedocs.io/en/latest/) | [CS229 Cheatsheet](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning) | [Google Scholar](https://scholar.google.co.in/) | [arXiv](https://arxiv.org/) | [UCI ML dataset repository](http://archive.ics.uci.edu/ml/index.php) | [CS229#Notes](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/CS229.pdf) 

âœ¿ [Official CS229 Notes](https://github.com/SKKSaikia/CS229_ML/tree/master/doc/cs229-notes-all) | [CS229 Notes by Shervine](https://stanford.edu/~shervine/teaching/cs-229.html) | [Machine learning study guides tailored to CS 229](https://stanford.edu/~shervine/teaching/cs-229/cheatsheet-supervised-learning) | [Derivatives Backpropagation and Vectorization](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/Derivatives%20Backpropagation%20and%20Vectorization.pdf) | [CS229 More Notes](https://github.com/SKKSaikia/CS229_ML/tree/master/doc/NOTES) - [Section Notes](https://github.com/SKKSaikia/CS229_ML/tree/master/doc/NOTES/section_notes) - [Supplementary Notes](https://github.com/SKKSaikia/CS229_ML/tree/master/doc/NOTES/supplementary_notes) | [CS229@2008](https://www.youtube.com/watch?v=UzxYlbK2c7E&list=PLA89DCFA6ADACE599) - [syllabus](https://github.com/SKKSaikia/CS229_ML/blob/master/cs229_2008.txt) | [Statistical Machine Learning CMU Spring 2016](http://academictorrents.com/details/07f1555918ed051809f0075fedc0cd469a194c93) | [MIT Course 9.520 - Statistical Learning Theory and Applications, Fall 2015	](http://academictorrents.com/details/8b47f45382645882a23e0f8d9d9fbb764b3eb378) | [Advanced Introduction to Machine Learning - CMU - Fall 2015](http://academictorrents.com/details/8165e591be4b54c2bc93b1e54c4374d42dcdd9f8)

âœ¿ <b>[Cheatsheets](https://github.com/SKKSaikia/CS229_ML/tree/master/doc/cheatsheets) : </b><br/>
ð“€¯ [Supervised Learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/cheatsheet-supervised-learning.pdf)
ð“€¯ [Unsupervised Learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/cheatsheet-unsupervised-learning.pdf)
ð“€¯ [Machine Learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/cheatsheet-machine-learning-tips-and-tricks.pdf)
ð“€¯ [Deep Learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/cheatsheet-deep-learning.pdf)
ð“€¯ [Algebra Calculus](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/refresher-algebra-calculus.pdf)
ð“€¯ [Probability Statistics](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/refresher-probabilities-statistics.pdf)
ð“€¯ [Combined](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/super-cheatsheet-machine-learning.pdf)
ð“€¯ [Machine Learning](https://github.com/SKKSaikia/CS229_ML/blob/master/doc/cheatsheets/machine-learning-cheat-sheet.pdf)
ð“€¯ [ML tools](https://github.com/SKKSaikia/CS229_ML/tree/master/doc/cheatsheets/ml_tool)

# FINAL PROJECT | [Past Projects](http://cs229.stanford.edu/projects.html)

CS229 gives a lot of importance to Final Project, going through the [past projects](http://cs229.stanford.edu/projects.html) , I was happy to see the dynamic range of wonderful ideas and application of ML all the way (I have the [list](https://github.com/SKKSaikia/CS229_ML/blob/master/CS229%20-%20Poster%20Session%20Number.xlsx) - [e.g](https://youtu.be/Iz_ifpoYE_g), [eg2](https://youtu.be/u5a7fz_NoB4)). Good CS229 projects are either publishable or minor changes to be able to publish the project. [NIPS (NeurIPS)](https://nips.cc/) , [ICML](https://icml.cc/) are the ML conferences to show ML works to other people around the world. I was ecstatic to start my own and did " ".
